---
layout: default
title: "뜨개질 인터랙티브 음악 (2025.12.)"
categories: [Creative Coding]
---

# 세 줄 요약

- 2025년 2학기 정보문화학 사운드인터랙션 과제로, 코바늘 동작에 반응하는 인터랙티브 음악을 Max/MSP와 Python 스크립트를 이용하여 작성하였음.
- mediapipe 라이브러리에서 받아온 값을 udp 통신으로 max에 넘기는 방식. 2024년도에 진행한 파워플랜트 스케일업 프로젝트 경험이 도움이 되었다.
- 흥미로운 인터랙션이란 무엇인지 고찰하였음. 사용자가 인터랙션을 완벽하게 이해할 수 있게 만들까 고민하기도 했지만 좀 더 창작자(본인)의 의도가 생성물에 반영되도록 함.

# 상세

Max/MSP를 이용한 인터랙티브 오디오를 한 번 작성해보고 싶어서 사운드인터랙션 수업을 수강하였다. 23년도에 파워플랜트에서 진행했던 프로젝트도 인터랙티브 오디오라고 할 수 있지만 당시에 나는 비주얼 부분을 중심으로 작업해서, 이번에는 오디오에 집중하여 작업하고자 했다. 4인 1조의 조별과제로 진행된 프로젝트였고, 내가 주제를 제안해서 팀원들을 모집한 것이었기에 적극적으로 프로젝트를 이끌어나가려고 노력했다. (나쁘게 말하면 다소 독단적으로?)

(결과 영상 OR 오디오 추후 탑재)

원래 하고 싶었던 것은 코바늘의 각각 동작에 소리가 매핑되어 재생되는 것이었다. 이를테면 실이 바늘에 감길 때, 바늘이 편물에 박힐 때, 그 순간 순간을 캐치해서 마치 스트리트 파이터 게임하는 것처럼 소리가 나오길 원했다. 그런데 실과 바늘 모두 굉장히 객체 인식하기 어려운 오브젝트라 원하는 대로 잘 되지 않았다. 만약에 실시간성을 요하는 작업이 아니었으면 조금 더 무거운 모델이나 정교한 방법론을 써서 보완할 수 있었겠지만, 라이브 인터랙티브 작업이라 결국 이와 같은 최초의 목표는 포기하게 되었다.

그 대신 mediapipe를 이용한 손가락 마디 좌표 인식 및 opencv를 이용한 컬러 기반 실 인식을 토대로 음악 생성 Max/MSP 패처를 작성하였다. 실은 무조건 검지 손가락에 걸려있기 때문에 그 근방을 ROI로 하면 실의 움직임을 어느 정도 확인할 수 있다. 바늘의 경우에도 잡고 있는 위치가 한정적이라 처음에 calibration을 해놓으면 오차는 있을지언정 tip의 움직임을 추적할 수 있다. 이와 같이 모든 event를 인식하는 대신 여러 물리량을 받아 음악을 생성하는 방식으로 음악 뜨개질 영상에 반응하도록 했다.

가장 구현에 공을 들인 부분은, 손가락에 걸린 실의 모양을 wavetable synth처럼 쓸 수 있도록 gen~ 오브젝트를 작성한 것이다. 다른 오브젝트들과는 작동 방식이 완전히 달라 구현하는 데 애를 먹었다. 실의 모양이 바뀔 때 이산적으로 파형이 바뀌지 않고 보간되도록 만들었다. 나중에 이를 이용하여 좀 더 재밌는 프로젝트를 해볼 수 있을 것 같다. 이것 외에도 MAX 패처에서는 여러 물리량을 UDP 통신으로 받아 미디 넘버 및 duration을 만들어내고, 베이스, 앰비언스를 결합 한 뒤 여러 이펙팅을 하여 생성한다. 어느 정도의 '듣기 좋음'을 구현하기 위해서 일정 간격마다 바뀌는 코드 진행 위에서 음을 만들어내도록 설계하였다.

고생하긴 했지만 그래도 재밌는 프로젝트였다. 실이라는 재료가 가지는 물성을 어떻게 센싱하여 컴퓨터로 넘겨줄 수 있는지 많은 고민을 해보았는데, 나중에 장력, 꼬임과 같은 좀 더 내가 생각하기에 '매력적인' 물성을 센싱하여 사용해보고 싶다.

# 여담

발표 영상을 제작하라고 해서 캡컷 TTS로 제작했다.