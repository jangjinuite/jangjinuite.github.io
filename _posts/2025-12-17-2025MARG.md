---
layout: default
title: "MARG 하계 방학 인턴 (2025.07.-2025.08.)"
categories: [Technical Experiences]
---

# 세 줄 요약

- 서울대학교 융합과학기술대학원 음악오디오연구실에서 2달 동안 인턴으로 연구하였음.
- 원래 오디오 도메인 위에서 라임(Rhyme)을 분석/생성하는 모델을 개발하고자 했으나, 여러 가지 이유로 난항을 겪고 주제를 변경함.
- 주제를 변경함. 신디사이저 파라미터 매칭 모델을 freeze하고 이를 보정하는 audio to audio 모델을 설계하고 학습시켰음.

# 상세

전역과 동시에 서울대 융합과학기술대학원 음악오디오연구실에서 2달 동안 하계 방학 인턴으로 연구하였음. 연구 주제를 연구실 차원에서 제시해주는 느낌이 아니었기 때문에, 직접 2달 간 주도적으로 문제를 설정하고 풀어나가는 경험을 해볼 수 있었음.

## 주제 1) 라임 분석 및 생성

원래 처음에는 TTS를 이용하여 라임을 충실히 반영한 랩 음성(혹은 가사)를 생성하는 모델을 만들고자 했음. 혹은 랩 음성 및 가사가 주어졌을 때 어느 부분이 라임인지 분석하는 모델을 만들고자 했음. (genius 영상들처럼) Wav2Vec과 Forced Alignment를 이용하여 모음 간의 유사도 행렬을 만들어서 라임 분석도 해보고, FastSpeech2의 phoneme embedding을 이용하여 모음의 길이를 조정하여 라임을 생성하는 등 여러 시도를 해봄. 그러나 여러 가지 어려움을 겪음.

1) 라임에 관한 메트릭이 부족함. 모음을 완전히 일치시켜야 라임인지, 모음 말고 자음의 유사성도 라임인지, 이런 것들을 순수히 내가 판단해야 돼서 연구의 객관성이 너무 떨어졌음.

2) 데이터가 너무 없다. 텍스트 도메인 위에서는 발음 기호로 하면 되는데, 내가 텍스트 도메인의 한계를 극복하기 위해서 오디오 도메인 위에서 라임을 분석하겠다고 한 거라 다른 데이터가 필요했음. 그렇다고 일일히 paired 데이터를 만드는 것도 무리고...

3) 그리고 무엇보다 연구의 당위성이 너무 떨어진다고 느꼈음. 왜 라이밍을 잘하는 모델을 만들어야 하지? 라임이라는 것이 그렇게 중요한가? 다른 참고 문헌을 찾아봤을 때는 라이밍의 분석을 통해 화자(그러니까 래퍼 혹은 가수) 특성을 파악할 수 있기 때문에 유용하다는 식으로 나와있던데 솔직히 공감이 잘 되지 않았다. 내가 생각했던 당초의 목표 중 하나는 라이밍을 잘 분석/생성할 수 있게 되면 데이터의 증강이 가능해질 것이고 이를 통해 더 정교한 라이밍을 만들어 낼 수 있다는 것이었다. 그런데 인터넷 포스트들을 뒤지다보니 오히려 '라이밍을 열심히 하지 않는게 더 세련된 음악이다'라는 의견도 있어서 연구를 계속하고 싶은 마음이 갈수록 줄어들었다.
   
그래서 주제를 변경하였다.

## 주제 2) 신디사이저 파라미터 매칭 모델을 보조하는 Audio to Audio 모델

원래부터 생각했던 주제 중 하나는 가상악기를 만드는 것이었음. 근데 이미 1번 주제를 하느라 시간을 몇 주 쓴 상태라 조금 길이 보이는 주제를 해야겠다는 생각이 들었음. 가상 악기 관련해서 재밌는 주제를 찾아보다가 연구실의 신원철 연구원님이 신디사이저의 파라미터 매칭에 관련하여 강화학습으로 문제를 풀어나가셨다는 사실을 알게 됨. 이거 성능이 상당히 좋았기 때문에 나는 이 모델이 내놓는 오디오를 빠르게 후보정하여 마치 신디사이저를 확장한 것 같이 쓸 수 있도록 만들어 봐야겠다는 생각을 함.

<a href="https://github.com/jangjinuite/SynthExtension">Github Repo</a> 들어가면 코드 확인 가능.

핵심적인 아이디어는 트랜스포머 구조를 이용하여 두 오디오 간의 관계를 나타내는 필터를 학습하는 것. 두 오디오 (실제 신디사이저 샘플과 파라미터 매칭 모델로 생성된 샘플) 간의 거리가 이미 파라미터 매칭을 통해 어느 정도 가까워진 상태기 때문에 이런 아이디어가 통할 수 있었다. 학습 열심히 돌리고 metric 측정한 결과 성능이 괜찮았음. 빠르고 가벼운 모델로 후보정을 할 수 있다는 점에서 의미가 있다고 생각했고, 처음에 의도했던 synth의 확장판으로써의 역할도 어느 정도 할 수 있었음.

다만 몇 가지 한계점이 있었는데 일단 노이즈가 종종 심하게 나타났음. 왜냐면 raw audio를 생성하는게 아니고 source의 스펙트로그램에 element wise하게 곱해지는 필터를 학습하는 것이기 때문에, 일부 구간에서 너무 극단적인 값으로 필터가 걸려버리면 그게 심한 노이즈로 나타남. 두 번째 한계는 데이터가 전부 C3이라서 다양한 피치에 대해서는 적용이 안 됨. Polyphonic은 당연히 안되고.. 이 문제는 왜 생기냐면 파라미터 매칭 모델은 애초에 음색을 모사하기 위한 모델이라서 굳이 여러 피치에 대해서 학습을 할 필요가 없는데 나의 모델은 synth를 확장하는 게 목적이기 때문임. 하지만 다양한 피치에 대해서 학습을 시도해보는 것은 시간이 너무 없었다..

(figure 하나 나중에 넣겠음)

## 결론

아무튼 그래도 두 달 간의 인턴십은 굉장히 의미 있었음. 연구가 어떤 식으로 이루어지는지도 (아주 겉핥기 식으로) 알 수 있었고, 다음 인턴십은 돈을 버는 데에 관심이 있는 회사에서 해보고 싶다는 생각도 함. 그리고 오디오 신호 처리에 관련된 스터디가 주 1회 진행되었는데 이게 굉장히 재밌었음. 오랜만에 공부를 하면서 정말 재밌다는 감상을 받음. 그래서 설레는 마음으로 학교에 가서 바로 5전공을 신청했지만 그 어떤 과목에도 재미를 느끼지 못하고 슬픔에 빠지게 되었다는 그런 이야기.

# 여담

연구실이 수원에 있다길래 수원시청에 두 달 동안 고시원을 다니기로 했는데, 고시원에서 연구실까지 버스 타고 30분 걸렸다. 근데 사당에서도 연구실까지 40분이면 간다는 사실을 나중에 알게 되었다.
